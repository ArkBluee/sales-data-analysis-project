{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed3609da",
   "metadata": {},
   "source": [
    "## **Data Cleaning**\n",
    "\n",
    "The raw dataset underwent several preprocessing steps, including the removal of duplicates, handling of null values, type conversions, and the extraction of structured information from text fields (e.g., date and address columns) to ensure accuracy and consistency in the analysis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f5985b",
   "metadata": {},
   "source": [
    "### **Importing Necessary Libraries**\n",
    "\n",
    "To initiate the data analysis, only the necessary Python library was imported. In this case, **pandas** was used for efficient data manipulation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50c476ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63293391",
   "metadata": {},
   "source": [
    "### **Pulling Raw Data**\n",
    "\n",
    "The raw sales data was imported into the workspace. This dataset contains transactional records including order details, product information, pricing, and customer purchase addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c366f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5fca1f",
   "metadata": {},
   "source": [
    "### **Initial Inspection of the Dataset**\n",
    "\n",
    "To understand the structure and contents of the dataset, the first five rows were displayed using the `.head()` method. This provides a quick overview of the columns, data types, and potential quality issues such as missing or inconsistent values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b8a65e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity Ordered</th>\n",
       "      <th>Price Each</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Purchase Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176558</td>\n",
       "      <td>USB-C Charging Cable</td>\n",
       "      <td>2</td>\n",
       "      <td>11.95</td>\n",
       "      <td>04/19/19 08:46</td>\n",
       "      <td>917 1st St, Dallas, TX 75001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176559</td>\n",
       "      <td>Bose SoundSport Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>99.99</td>\n",
       "      <td>04/07/19 22:30</td>\n",
       "      <td>682 Chestnut St, Boston, MA 02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176560</td>\n",
       "      <td>Google Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>04/12/19 14:38</td>\n",
       "      <td>669 Spruce St, Los Angeles, CA 90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176560</td>\n",
       "      <td>Wired Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>11.99</td>\n",
       "      <td>04/12/19 14:38</td>\n",
       "      <td>669 Spruce St, Los Angeles, CA 90001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Order ID                     Product Quantity Ordered Price Each  \\\n",
       "0   176558        USB-C Charging Cable                2      11.95   \n",
       "1      NaN                         NaN              NaN        NaN   \n",
       "2   176559  Bose SoundSport Headphones                1      99.99   \n",
       "3   176560                Google Phone                1        600   \n",
       "4   176560            Wired Headphones                1      11.99   \n",
       "\n",
       "       Order Date                      Purchase Address  \n",
       "0  04/19/19 08:46          917 1st St, Dallas, TX 75001  \n",
       "1             NaN                                   NaN  \n",
       "2  04/07/19 22:30     682 Chestnut St, Boston, MA 02215  \n",
       "3  04/12/19 14:38  669 Spruce St, Los Angeles, CA 90001  \n",
       "4  04/12/19 14:38  669 Spruce St, Los Angeles, CA 90001  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6472fda",
   "metadata": {},
   "source": [
    "### **Column Name Standardization**\n",
    "\n",
    "To ensure consistency and avoid potential issues during analysis, all column names were standardized. This includes:\n",
    "\n",
    "- Removing leading/trailing whitespaces\n",
    "- Converting all names to lowercase\n",
    "- Replacing spaces with underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1b629a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting column names\n",
    "\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a254eb50",
   "metadata": {},
   "source": [
    "### **Checking and Dropping Completely Null Rows**\n",
    "\n",
    "To identify and remove rows that contain only missing values across all columns, the following check was performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69abd408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null rows\n",
    "df[df.isna().all(axis=1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed4c2c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8192abd4",
   "metadata": {},
   "source": [
    "### **Missing Values Per Column**\n",
    "\n",
    "To assess the completeness of the dataset, the number of missing values in each column was calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd0e77bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id            0\n",
       "product             0\n",
       "quantity_ordered    0\n",
       "price_each          0\n",
       "order_date          0\n",
       "purchase_address    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5a69c",
   "metadata": {},
   "source": [
    "### **Checking for Duplicate Rows**\n",
    "\n",
    "Since there are no missing values in any column, the next step is to identify any duplicate entries in the dataset. Duplicate rows can skew analysis, especially in aggregations and trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77a2f679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(618)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a718a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity_ordered</th>\n",
       "      <th>price_each</th>\n",
       "      <th>order_date</th>\n",
       "      <th>purchase_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>176585</td>\n",
       "      <td>Bose SoundSport Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>99.99</td>\n",
       "      <td>04/07/19 11:31</td>\n",
       "      <td>823 Highland St, Boston, MA 02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>176585</td>\n",
       "      <td>Bose SoundSport Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>99.99</td>\n",
       "      <td>04/07/19 11:31</td>\n",
       "      <td>823 Highland St, Boston, MA 02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Order ID</td>\n",
       "      <td>Product</td>\n",
       "      <td>Quantity Ordered</td>\n",
       "      <td>Price Each</td>\n",
       "      <td>Order Date</td>\n",
       "      <td>Purchase Address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>Order ID</td>\n",
       "      <td>Product</td>\n",
       "      <td>Quantity Ordered</td>\n",
       "      <td>Price Each</td>\n",
       "      <td>Order Date</td>\n",
       "      <td>Purchase Address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>Order ID</td>\n",
       "      <td>Product</td>\n",
       "      <td>Quantity Ordered</td>\n",
       "      <td>Price Each</td>\n",
       "      <td>Order Date</td>\n",
       "      <td>Purchase Address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186738</th>\n",
       "      <td>Order ID</td>\n",
       "      <td>Product</td>\n",
       "      <td>Quantity Ordered</td>\n",
       "      <td>Price Each</td>\n",
       "      <td>Order Date</td>\n",
       "      <td>Purchase Address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186781</th>\n",
       "      <td>259296</td>\n",
       "      <td>Apple Airpods Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>09/28/19 16:48</td>\n",
       "      <td>894 6th St, Dallas, TX 75001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186782</th>\n",
       "      <td>259296</td>\n",
       "      <td>Apple Airpods Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>09/28/19 16:48</td>\n",
       "      <td>894 6th St, Dallas, TX 75001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186784</th>\n",
       "      <td>259297</td>\n",
       "      <td>Lightning Charging Cable</td>\n",
       "      <td>1</td>\n",
       "      <td>14.95</td>\n",
       "      <td>09/15/19 18:54</td>\n",
       "      <td>138 Main St, Boston, MA 02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186785</th>\n",
       "      <td>259297</td>\n",
       "      <td>Lightning Charging Cable</td>\n",
       "      <td>1</td>\n",
       "      <td>14.95</td>\n",
       "      <td>09/15/19 18:54</td>\n",
       "      <td>138 Main St, Boston, MA 02215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>883 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        order_id                     product  quantity_ordered  price_each  \\\n",
       "30        176585  Bose SoundSport Headphones                 1       99.99   \n",
       "31        176585  Bose SoundSport Headphones                 1       99.99   \n",
       "519     Order ID                     Product  Quantity Ordered  Price Each   \n",
       "1149    Order ID                     Product  Quantity Ordered  Price Each   \n",
       "1155    Order ID                     Product  Quantity Ordered  Price Each   \n",
       "...          ...                         ...               ...         ...   \n",
       "186738  Order ID                     Product  Quantity Ordered  Price Each   \n",
       "186781    259296    Apple Airpods Headphones                 1         150   \n",
       "186782    259296    Apple Airpods Headphones                 1         150   \n",
       "186784    259297    Lightning Charging Cable                 1       14.95   \n",
       "186785    259297    Lightning Charging Cable                 1       14.95   \n",
       "\n",
       "            order_date                   purchase_address  \n",
       "30      04/07/19 11:31  823 Highland St, Boston, MA 02215  \n",
       "31      04/07/19 11:31  823 Highland St, Boston, MA 02215  \n",
       "519         Order Date                   Purchase Address  \n",
       "1149        Order Date                   Purchase Address  \n",
       "1155        Order Date                   Purchase Address  \n",
       "...                ...                                ...  \n",
       "186738      Order Date                   Purchase Address  \n",
       "186781  09/28/19 16:48       894 6th St, Dallas, TX 75001  \n",
       "186782  09/28/19 16:48       894 6th St, Dallas, TX 75001  \n",
       "186784  09/15/19 18:54      138 Main St, Boston, MA 02215  \n",
       "186785  09/15/19 18:54      138 Main St, Boston, MA 02215  \n",
       "\n",
       "[883 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting duplicates\n",
    "\n",
    "df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b6427",
   "metadata": {},
   "source": [
    "### **Removing Duplicate Rows**\n",
    "\n",
    "After identifying the number of duplicate rows, they were removed to ensure data accuracy and integrity using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2e4edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ce9a29",
   "metadata": {},
   "source": [
    "### **Inspecting Column Data Types**\n",
    "\n",
    "To understand the structure of the dataset, the data types of each column were checked using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bec4ef5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id            object\n",
       "product             object\n",
       "quantity_ordered    object\n",
       "price_each          object\n",
       "order_date          object\n",
       "purchase_address    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking data types\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09358bca",
   "metadata": {},
   "source": [
    "### **Converting Column Data Types**\n",
    "\n",
    "Several columns were found to have incorrect data types that could affect calculations and time-based analysis:\n",
    "\n",
    "- `order_id`, `quantity_ordered` were stored as object types instead of integers.\n",
    "- `price_each` was stored as an object instead of float.\n",
    "- `order_date` was stored as an object instead of `datetime`.\n",
    "\n",
    "To fix this, the following conversions were applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe09ff6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Order ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Supposed to be converting to right data types\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33morder_id\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43morder_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mquantity_ordered\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mquantity_ordered\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      5\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mprice_each\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mprice_each\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\generic.py:6662\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6656\u001b[39m     results = [\n\u001b[32m   6657\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6658\u001b[39m     ]\n\u001b[32m   6660\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6661\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6662\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6663\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6664\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    428\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\internals\\blocks.py:784\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    781\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    782\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    788\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m     values = values.astype(dtype, copy=copy)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     values = \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    132\u001b[39m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arr.astype(dtype, copy=copy)\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: 'Order ID'"
     ]
    }
   ],
   "source": [
    "# Supposed to be converting to right data types\n",
    "\n",
    "df['order_id'] = df['order_id'].astype(int)\n",
    "df['quantity_ordered'] = df['quantity_ordered'].astype(int)\n",
    "df['price_each'] = df['price_each'].astype(float)\n",
    "df['order_date'] = pd.to_datetime(df['order_date'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d97b80",
   "metadata": {},
   "source": [
    "### **Inspecting Data Type Conversion Error**\n",
    "\n",
    "During the data type conversion process, an error was encountered in the `order_id` column. Specifically, the column contained an object value `'Order ID'`, which is not compatible with integer conversion.\n",
    "\n",
    "This issue typically arises from duplicated header rows within the dataset. To investigate the cause, the following command was used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db7fd657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity_ordered</th>\n",
       "      <th>price_each</th>\n",
       "      <th>order_date</th>\n",
       "      <th>purchase_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Order ID</td>\n",
       "      <td>Product</td>\n",
       "      <td>Quantity Ordered</td>\n",
       "      <td>Price Each</td>\n",
       "      <td>Order Date</td>\n",
       "      <td>Purchase Address</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     order_id  product  quantity_ordered  price_each  order_date  \\\n",
       "519  Order ID  Product  Quantity Ordered  Price Each  Order Date   \n",
       "\n",
       "     purchase_address  \n",
       "519  Purchase Address  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['order_id'] == 'Order ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e17aa97",
   "metadata": {},
   "source": [
    "### **Dropping Invalid Header Row**\n",
    "\n",
    "The inspection revealed that the row containing `'Order ID'` in the `order_id` column was a duplicated header row with no valid data.\n",
    "Since this row does not contain any necessary or usable data, it was removed from the dataset using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7fa588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with 'Order ID' value in order_id column\n",
    "\n",
    "df.drop(df[df['order_id'] == 'Order ID'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caef06e7",
   "metadata": {},
   "source": [
    "### **Converting Data Types**\n",
    "\n",
    "After cleaning the data and removing invalid entries, the necessary columns were converted to appropriate data types to enable accurate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3662f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Data types\n",
    "\n",
    "df['order_id'] = df['order_id'].astype(int)\n",
    "df['quantity_ordered'] = df['quantity_ordered'].astype(int)\n",
    "df['price_each'] = df['price_each'].astype(float)\n",
    "df['order_date'] = pd.to_datetime(df['order_date'], format='%m/%d/%y %H:%M')\n",
    "df['purchase_address'] = df['purchase_address'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ceab2a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                     int64\n",
       "product                     object\n",
       "quantity_ordered             int64\n",
       "price_each                 float64\n",
       "order_date          datetime64[ns]\n",
       "purchase_address            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbb0309",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### **Splitting Address into Components**\n",
    "\n",
    "The `purchase_address` column was split into three parts to extract key location details. This separation provided individual columns for the street, city, and a combined state and ZIP code. Extracting these components helps enable deeper geographic analysis in later stages of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "99adf8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting street and city\n",
    "address_split = df['purchase_address'].str.split(',',expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a99e3a",
   "metadata": {},
   "source": [
    "###  **Inspecting `purchase_address` Format**\n",
    "\n",
    "A sample of the `purchase_address` column was reviewed to understand its structure and confirm consistency. This inspection served as a reference for accurately extracting the `street` and `city` components in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "06502c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            917 1st St, Dallas, TX 75001\n",
       "2       682 Chestnut St, Boston, MA 02215\n",
       "3    669 Spruce St, Los Angeles, CA 90001\n",
       "4    669 Spruce St, Los Angeles, CA 90001\n",
       "5       333 8th St, Los Angeles, CA 90001\n",
       "Name: purchase_address, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['purchase_address'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7550d",
   "metadata": {},
   "source": [
    "###  **Assigning Street and City**\n",
    "\n",
    "After splitting the `purchase_address`, the street number was removed to isolate the street name. The `city` was directly assigned from the second part of the split:\n",
    "\n",
    "- `street`: Extracted by removing the leading house number from the address.\n",
    "- `city`: Directly taken from the second element of the split string.\n",
    "\n",
    "This prepares the data for city-level analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63eee39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st St</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chestnut St</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spruce St</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spruce St</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8th St</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186845</th>\n",
       "      <td>Highland St</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186846</th>\n",
       "      <td>Dogwood St</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186847</th>\n",
       "      <td>12th St</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186848</th>\n",
       "      <td>Forest St</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186849</th>\n",
       "      <td>Meadow St</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185686 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             street            city\n",
       "0            1st St          Dallas\n",
       "2       Chestnut St          Boston\n",
       "3         Spruce St     Los Angeles\n",
       "4         Spruce St     Los Angeles\n",
       "5            8th St     Los Angeles\n",
       "...             ...             ...\n",
       "186845  Highland St     Los Angeles\n",
       "186846   Dogwood St   San Francisco\n",
       "186847      12th St   San Francisco\n",
       "186848    Forest St   San Francisco\n",
       "186849    Meadow St   San Francisco\n",
       "\n",
       "[185686 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigning street and city\n",
    "df['street'] = address_split[0].str.replace(r'^\\d+\\s+', '', regex=True)\n",
    "df['city'] = address_split[1]\n",
    "\n",
    "\n",
    "df[['street', 'city']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5b57a0",
   "metadata": {},
   "source": [
    "### **Mapping State Abbreviations to Full Names**\n",
    "\n",
    "To enhance readability and consistency in the dataset, a dictionary was created to map U.S. state abbreviations (e.g., `CA`, `NY`) to their full state names (e.g., `California`, `New York`). This mapping supports clearer analysis and visualization at the state level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5195d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating state abbreviations dictionary\n",
    "\n",
    "us_state_abbrev = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas',\n",
    "    'CA': 'California', 'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware',\n",
    "    'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho',\n",
    "    'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas',\n",
    "    'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi',\n",
    "    'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York',\n",
    "    'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah',\n",
    "    'VT': 'Vermont', 'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin', 'WY': 'Wyoming', 'DC': 'District of Columbia'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad0efc",
   "metadata": {},
   "source": [
    "### **Extracting State and ZIP Code**\n",
    "\n",
    "The third part of the `purchase_address` string was split to isolate the **state abbreviation** and **ZIP code**. Additional columns were created:\n",
    "\n",
    "- `state`: Extracted state abbreviation (e.g., `CA`).\n",
    "- `state_name`: Mapped full state name using a predefined dictionary.\n",
    "- `zip`: Extracted ZIP code for more granular geographic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c97a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting state and zip\n",
    "state_zip_split = address_split[2].str.strip().str.split(' ', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c371c764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating State, State Name, and ZIP columns\n",
    "\n",
    "df['state'] = state_zip_split[0]\n",
    "df['state_name'] = df['state'].map(us_state_abbrev)\n",
    "\n",
    "df['zip'] = state_zip_split[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3019676",
   "metadata": {},
   "source": [
    "### **Creating the Sales Column**\n",
    "\n",
    "A new column `sales` was created by multiplying `quantity_ordered` and `price_each`. This represents the total revenue generated per transaction and is essential for revenue-based analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e948b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales column\n",
    "df['sales'] = df['quantity_ordered'] * df['price_each']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16641f87",
   "metadata": {},
   "source": [
    "### **Extracting Date and Time Components**\n",
    "\n",
    "The `order_date` column was decomposed into multiple time-based features for more granular temporal analysis:\n",
    "\n",
    "- `month`: Numeric month (e.g., 1 for January)\n",
    "- `month_name`: Full month name (e.g., \"January\")\n",
    "- `year`: Year of the order\n",
    "- `hour`: Hour of the day the order was placed\n",
    "- `day_of_week`: Name of the day (e.g., \"Monday\")\n",
    "\n",
    "These columns are useful for identifying trends and patterns across different time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2911c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating date parts into columns\n",
    "\n",
    "df['month'] = df['order_date'].dt.month\n",
    "df['month_name'] = df['order_date'].dt.month_name()\n",
    "df['year'] = df['order_date'].dt.year\n",
    "\n",
    "df['hour'] = df['order_date'].dt.hour\n",
    "df['day_of_week'] = df['order_date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb007b0",
   "metadata": {},
   "source": [
    "### **Extracting Additional Time Features**\n",
    "\n",
    "Further time-based features were extracted from the `order_date` column:\n",
    "\n",
    "- `year`: The year of each order.\n",
    "- `hour`: The hour the order was placed, useful for identifying peak order times.\n",
    "- `day_of_week`: The day name (e.g., Monday, Tuesday), helpful for analyzing weekly trends.\n",
    "\n",
    "These features enhance temporal insights during exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e4e8769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['order_date'].dt.year\n",
    "\n",
    "df['hour'] = df['order_date'].dt.hour\n",
    "df['day_of_week'] = df['order_date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef3eb31",
   "metadata": {},
   "source": [
    "### **Checking for Invalid Numerical Values**\n",
    "\n",
    "The dataset was inspected for negative or zero values in key numerical columns that should only contain positive values:\n",
    "\n",
    "- `quantity_ordered` ≤ 0  \n",
    "- `price_each` ≤ 0  \n",
    "- `sales` ≤ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2a9cea6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity_ordered</th>\n",
       "      <th>price_each</th>\n",
       "      <th>order_date</th>\n",
       "      <th>purchase_address</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>state_name</th>\n",
       "      <th>zip</th>\n",
       "      <th>sales</th>\n",
       "      <th>month</th>\n",
       "      <th>month_name</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [order_id, product, quantity_ordered, price_each, order_date, purchase_address, street, city, state, state_name, zip, sales, month, month_name, year, hour, day_of_week]\n",
       "Index: []"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for negative numerical values\n",
    "\n",
    "df[df['quantity_ordered'] <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8ebc3a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity_ordered</th>\n",
       "      <th>price_each</th>\n",
       "      <th>order_date</th>\n",
       "      <th>purchase_address</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>state_name</th>\n",
       "      <th>zip</th>\n",
       "      <th>sales</th>\n",
       "      <th>month</th>\n",
       "      <th>month_name</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [order_id, product, quantity_ordered, price_each, order_date, purchase_address, street, city, state, state_name, zip, sales, month, month_name, year, hour, day_of_week]\n",
       "Index: []"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['price_each'] <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "db1f800e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity_ordered</th>\n",
       "      <th>price_each</th>\n",
       "      <th>order_date</th>\n",
       "      <th>purchase_address</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>state_name</th>\n",
       "      <th>zip</th>\n",
       "      <th>sales</th>\n",
       "      <th>month</th>\n",
       "      <th>month_name</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [order_id, product, quantity_ordered, price_each, order_date, purchase_address, street, city, state, state_name, zip, sales, month, month_name, year, hour, day_of_week]\n",
       "Index: []"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['sales'] <= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb803c37",
   "metadata": {},
   "source": [
    "### **Sorting the Data by Order Date**\n",
    "\n",
    "To ensure chronological consistency for time-based analysis, the dataset was sorted in ascending order based on the `order_date` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6fa15467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date\n",
    "\n",
    "df.sort_values('order_date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e1336",
   "metadata": {},
   "source": [
    "### **Exporting the Cleaned Dataset**\n",
    "\n",
    "The cleaned dataset was exported to a CSV file for use in further analysis and dashboard development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "01515a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f587f54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Wrapping Up Data Cleaning**\n",
    "\n",
    "The data cleaning process ensured that the dataset was accurate, consistent, and suitable for analysis. The key steps included:\n",
    "\n",
    "- Handling missing and duplicate values  \n",
    "- Correcting data types for numerical and datetime fields  \n",
    "- Parsing structured information from the address column  \n",
    "- Removing invalid records (e.g., non-numeric values or improperly formatted rows)  \n",
    "- Creating derived columns for enhanced analysis (e.g., `sales`, `month_name`, `state_name`)  \n",
    "\n",
    "With these steps completed, the dataset is now well-structured and ready for exploratory data analysis and visualization.\n",
    "\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
